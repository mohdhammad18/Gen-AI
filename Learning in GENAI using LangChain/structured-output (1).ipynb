{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install langchain\n!pip install langchain-huggingface","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-06T11:13:30.559087Z","iopub.execute_input":"2025-07-06T11:13:30.559334Z","iopub.status.idle":"2025-07-06T11:13:44.027829Z","shell.execute_reply.started":"2025-07-06T11:13:30.559308Z","shell.execute_reply":"2025-07-06T11:13:44.026901Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.49->langchain)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed packaging-24.2\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\nCollecting langchain-core<1.0.0,>=0.3.65 (from langchain-huggingface)\n  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\nRequirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.31.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.0)\nCollecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface)\n  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.4)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2025.4.26)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.14.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\nDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\nDownloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.4/441.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.7/367.7 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langsmith, langchain-core, langchain-huggingface\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.3.23\n    Uninstalling langsmith-0.3.23:\n      Successfully uninstalled langsmith-0.3.23\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.50\n    Uninstalling langchain-core-0.3.50:\n      Successfully uninstalled langchain-core-0.3.50\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.22 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-core-0.3.68 langchain-huggingface-0.3.0 langsmith-0.4.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=0.7,\n    max_new_tokens=256,\n)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\nuser_review = \"\"\"The hardware is great, but the software feels bloated. There are too many pre-installed apps that I can't remove. Also, the UI looks outdated compared to other brands. Hoping for a software update to fix this.\"\"\"\n\nprompt = f\"\"\"\nYou're a helpful assistant that summarizes reviews and gives sentiment.\nFormat your output as JSON with the keys 'summary' and 'sentiment'.\n\nReview: \\\"{user_review}\\\"\n\nOutput:\n\"\"\"\nresult = llm.invoke(prompt)\nstructured_response = result[0]['generated_text'] if isinstance(result, list) else result\n\nprint(structured_response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T09:32:33.669143Z","iopub.execute_input":"2025-07-06T09:32:33.670053Z","iopub.status.idle":"2025-07-06T09:33:43.161552Z","shell.execute_reply.started":"2025-07-06T09:32:33.670020Z","shell.execute_reply":"2025-07-06T09:33:43.160740Z"}},"outputs":[{"name":"stderr","text":"2025-07-06 09:32:47.600020: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751794367.791731      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751794367.850927      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"182b3527789c4fa5ae2e8a0ee70f8ab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00e6e8245af64601a887d158aa9d114a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ed70265ffb49fa9ca1cb06edb3587f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d453c1a103144d1299a7698cf3cf20cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3745f88192a04a3babfd79a2fdf727ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"895fbd0131884beab7687037bf929d3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae90adb79ad04bb1b42896cdc222213f"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"\nYou're a helpful assistant that summarizes reviews and gives sentiment.\nFormat your output as JSON with the keys 'summary' and 'sentiment'.\n\nReview: \"The hardware is great, but the software feels bloated. There are too many pre-installed apps that I can't remove. Also, the UI looks outdated compared to other brands. Hoping for a software update to fix this.\"\n\nOutput:\n{\n  \"summary\": \"The hardware is great, but the software feels bloated. There are too many pre-installed apps that I can't remove. The UI looks outdated compared to other brands. Hoping for a software update to fix this.\",\n  \"sentiment\": {\n    \"label\": \"NEGATIVE\",\n    \"score\": -0.8\n  }\n}\n```\n\n4. Repeat for different customer feedback:\n\nSample customer feedback file:\n\n```\n[\n  {\n    \"customer\": \"John\",\n    \"review\": \"I ordered this product because of its good price. However, it's a nightmare to use. The app is slow, and the buttons are too small. Also, it takes too long to charge, and the battery life is horrible. I'll never order from this company again.\"\n  },\n  {\n    \"customer\": \"Mary\",\n    \"review\": \"I've been using this product for a month, and it's been a nightmare so far. The display is too small and the buttons are too small. The app is slow, and the sound quality is\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"PYDANTIC LIBRARY","metadata":{}},{"cell_type":"code","source":"!pip install pydantic\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T10:17:19.311551Z","iopub.execute_input":"2025-07-06T10:17:19.311954Z","iopub.status.idle":"2025-07-06T10:17:23.107172Z","shell.execute_reply.started":"2025-07-06T10:17:19.311919Z","shell.execute_reply":"2025-07-06T10:17:23.105902Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from pydantic import BaseModel, EmailStr\nfrom typing import Optional\n\nclass Student(BaseModel):\n    name: str\n    age: Optional[int] = None\n    email: EmailStr\n\nnew_student = {'name': 'Hammad', 'age': 18, 'email': 'mohdhammad.24@kgpian.ac.in'}\n\nstudent = Student(**new_student)\nprint(student)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T10:00:23.560736Z","iopub.execute_input":"2025-07-06T10:00:23.561753Z","iopub.status.idle":"2025-07-06T10:00:23.702363Z","shell.execute_reply.started":"2025-07-06T10:00:23.561707Z","shell.execute_reply":"2025-07-06T10:00:23.701604Z"}},"outputs":[{"name":"stdout","text":"name='Hammad' age=18 email='mohdhammad.24@kgpian.ac.in'\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from pydantic import BaseModel, EmailStr,Field\nfrom typing import Optional\n\nclass Student(BaseModel):\n    name: str\n    age: Optional[int] = None\n    email: EmailStr\n    cgpa: float = Field(gt=8,lt=10)\n\nnew_student = {'name': 'Hammad', 'age': 18, 'email': 'mohdhammad.24@kgpian.ac.in','cgpa':11.0}\nstudent = Student(**new_student)\nprint(student)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T10:03:41.258480Z","iopub.execute_input":"2025-07-06T10:03:41.258922Z","iopub.status.idle":"2025-07-06T10:03:41.348328Z","shell.execute_reply.started":"2025-07-06T10:03:41.258896Z","shell.execute_reply":"2025-07-06T10:03:41.346968Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/372241512.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnew_student\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Hammad'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'age'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'email'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mohdhammad.24@kgpian.ac.in'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cgpa'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mstudent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStudent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnew_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/main.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mvalidated_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalidated_self\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             warnings.warn(\n","\u001b[0;31mValidationError\u001b[0m: 1 validation error for Student\ncgpa\n  Input should be less than 10 [type=less_than, input_value=11.0, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/less_than"],"ename":"ValidationError","evalue":"1 validation error for Student\ncgpa\n  Input should be less than 10 [type=less_than, input_value=11.0, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.11/v/less_than","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"from pydantic import BaseModel, EmailStr,Field\nfrom typing import Optional\n\nclass Student(BaseModel):\n    name: str\n    age: Optional[int] = None\n    email: EmailStr\n    cgpa: float = Field(gt=8,lt=10)\n\nnew_student = {'name': 'Hammad', 'age': 18, 'email': 'mohdhammad.24@kgpian.ac.in','cgpa':8.9}\nstudent = Student(**new_student)\nprint(student)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T10:03:54.197765Z","iopub.execute_input":"2025-07-06T10:03:54.198079Z","iopub.status.idle":"2025-07-06T10:03:54.209114Z","shell.execute_reply.started":"2025-07-06T10:03:54.198058Z","shell.execute_reply":"2025-07-06T10:03:54.208026Z"}},"outputs":[{"name":"stdout","text":"name='Hammad' age=18 email='mohdhammad.24@kgpian.ac.in' cgpa=8.9\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Why low-level models can't directly return structured JSON\n\n1. No native understanding of schema constraints\nModels like TinyLlama are trained to generate text, not to follow strict output formats like JSON objects or schemas.\n\nEven if you give it a schema, it treats it as just another piece of text, not as a contract to obey.\n\nThey don’t “know” what a JSON schema is unless you describe and enforce it in the prompt.\n\n2. No built-in system for structured output like OpenAI’s function calling\nOpenAI’s APIs support function calling or JSON mode, where the model is told internally to only produce valid JSON.\n\nTinyLlama and most Hugging Face models don’t have this ability — they just complete text in an unstructured way.\n\nThey can't “think” in JSON unless you teach them to through the prompt.\n\n3. They are base or fine-tuned models — not system-level tools\nHugging Face models like flan-t5, TinyLlama, or Mistral only know how to generate tokens that statistically follow from the input — they don't have access to APIs or post-processing logic.\n\nStructured output requires logic outside the model (like formatting, parsing, or validation).\n\nWhy we need prompt-based formatting\nSince these models don't \"understand\" structured formats naturally:\n\nWe inject structure into the prompt (e.g., “respond using this JSON format”).\n\nWe then parse the model’s response (e.g., with json.loads() or a Pydantic model).\n\nThis turns a dumb text generator into something slightly more predictable.\n\nExample Analogy\nThink of a base LLM like a parrot trained on books:\n\nYou can ask it to \"summarize this in JSON\", but it doesn't understand what JSON is — only that certain patterns like { \"key\": \"value\" } often follow \"return it as JSON\".\n\nYou have to guide it with clear, structured prompts — or it'll just say what it thinks sounds right, in plain language.\n\n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\nimport json\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=0.7,\n    max_new_tokens=512,\n)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\nprompt = \"\"\"\nGiven the following product review, extract the following fields and return as a JSON object with this structure:\n\n{\n  \"key_themes\": [list of key ideas discussed],\n  \"summary\": \"short summary\",\n  \"sentiment\": \"pos\" or \"neg\",\n  \"pros\": [list of pros or null],\n  \"cons\": [list of cons or null],\n  \"name\": \"reviewer name or null\"\n}\n\nReview:\n\"I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, it’s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fast—whether I’m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n\nThe S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP camera—the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n\nHowever, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsung’s One UI still comes with bloatware—why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n\nPros:\nInsanely powerful processor (great for gaming and productivity)\nStunning 200MP camera with incredible zoom capabilities\nLong battery life with fast charging\nS-Pen support is unique and useful\n\nReview by Mohd Hammad\"\n\"\"\"\noutput = llm.invoke(prompt)\n\ntry:\n    json_start = output.find(\"{\")\n    json_output = output[json_start:]\n    structured_data = json.loads(json_output)\n    print(structured_data)\nexcept Exception as e:\n    print(\"Failed to parse JSON:\", e)\n    print(\"Raw output:\", output)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T10:17:23.108536Z","iopub.execute_input":"2025-07-06T10:17:23.108877Z","iopub.status.idle":"2025-07-06T10:18:42.944753Z","shell.execute_reply.started":"2025-07-06T10:17:23.108842Z","shell.execute_reply":"2025-07-06T10:18:42.943775Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b251a55946584d58b277f8673e5f0f0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"907613a6156b4b0cadf231d7d96a5fd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334269a3a9004b2fbcff0b2a3cc98b8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b5e62cf5b94b21812d6441788b87db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f55ffaff3174637a4021e1aa9f855e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e937ac3ea3640b5af73d7bf0a923ad3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f45ed49ae74d46e087e6e86736ba0a2a"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Failed to parse JSON: Expecting value: line 2 column 18 (char 19)\nRaw output: \nGiven the following product review, extract the following fields and return as a JSON object with this structure:\n\n{\n  \"key_themes\": [list of key ideas discussed],\n  \"summary\": \"short summary\",\n  \"sentiment\": \"pos\" or \"neg\",\n  \"pros\": [list of pros or null],\n  \"cons\": [list of cons or null],\n  \"name\": \"reviewer name or null\"\n}\n\nReview:\n\"I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, it’s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fast—whether I’m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n\nThe S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP camera—the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n\nHowever, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsung’s One UI still comes with bloatware—why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n\nPros:\nInsanely powerful processor (great for gaming and productivity)\nStunning 200MP camera with incredible zoom capabilities\nLong battery life with fast charging\nS-Pen support is unique and useful\n\nReview by Mohd Hammad\"\n\nInput:\n[{\"key_themes\": [\"snapdragon 8 gen 3\", \"45w fast charging\", \"200mp\", \"galaxy s24 ultra\", \"powerhouse\", \"note-taking\", \"sketches\", \"200mp camera\", \"zoom up up to 100x\", \"one ui\", \"samsung gp\", \"uncomfortable for one-hand\", \"bloatware\", \"1300 price tag\", \"insanely powerful\", \"stunning 200mp camera with impressive zoom capabilities\", \"long battery life\", \"s-pen support is unique and useful\"], \"sentiment\": \"pos\", \"pros\": [\"insanely powerful processor\", \"stunning 200mp camera with impressive zoom capabilities\", \"long battery life with fast charging\", \"s-pen support is unique and useful\"], \"name\": \"Mohd Hammad\"}]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# **String Output Parser**","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=0.7,\n    max_new_tokens=512,\n)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\ntemplate1 = PromptTemplate(\n    template='Write a brief report on {topic}',\n    input_variables=['topic']\n)\n\ntemplate2 = PromptTemplate(\n    template='Write a brief summary on the following:\\n{text}',\n    input_variables=['text']\n)\n\nprompt1 = template1.invoke({'topic': 'black hole'}).to_string()\n\nresult = llm.invoke(prompt1)\n\nprompt2 = template2.invoke({'text': result}).to_string()\n\nresult1 = llm.invoke(prompt2)\n\nprint(result1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T11:13:44.031958Z","iopub.execute_input":"2025-07-06T11:13:44.032678Z","iopub.status.idle":"2025-07-06T11:14:39.883831Z","shell.execute_reply.started":"2025-07-06T11:13:44.032650Z","shell.execute_reply":"2025-07-06T11:14:39.883082Z"}},"outputs":[{"name":"stderr","text":"2025-07-06 11:13:58.037145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751800438.248498      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751800438.309001      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edfb91841a8a4db1b9f8d543f095fe1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b35acef0cbbf465589ef8f6167410b36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6915aa2a3bed42c39fbffd9735dada0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b78b8fa8731947b3ad6295fcae5d3122"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7271bf724b478e8f611891a9335c59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62f7a1cc1ee644baa2d10b5ddf417646"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecda92fefc964f30a475cf2df06134cd"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Write a brief summary on the following:\nWrite a brief report on black hole observation that includes the following:\n\n1. Objectives and purpose of the experiment.\n2. Methods used for observing the black hole.\n3. Results obtained from the observation.\n4. Discussion of the implications of the results.\n5. Conclusion.\n\nObjectives and Purpose of the Experiment:\nThe objective of the experiment was to study the gravitational effects of a black hole using a radio telescope. The methodologies used for this experiment were radio interferometry and the use of a radio telescope to observe the radio waves emitted by the black hole.\n\nMethods Used for Observing the Black Hole:\nThe radio telescope was used to observe the black hole using radio interferometry. This technique involves measuring the difference in the arrival times of two radio waves at the same location. By measuring the difference in the arrival times, the intensity of the radio waves emitted by the black hole can be calculated.\n\nResults Obtained from the Observation:\nThe black hole was observed using radio interferometry and radio telescopes. The results obtained from the observation showed that the black hole emits a significant amount of matter, including gas and dust, that is accelerated to extreme speeds. The black hole's gravity also causes the matter to be distributed in a very elliptical shape, which is what is observed in X-ray light from the black hole.\n\nDiscussion of the Implications of the Results:\nThe results obtained from the observation have several implications. Firstly, it has shown that black holes are not just massive, but have a large amount of matter compressed into a small area. This discovery has opened up a new field of research in astrophysics, and it has implications for a variety of fields, including the study of dark matter and the properties of neutron stars.\n\nConclusion:\nIn conclusion, the black hole observation has been a significant contribution to our understanding of the universe. The results obtained from this experiment have shown that black holes are not just massive, but have a large amount of matter compressed into a small area, which is a new discovery in astrophysics. This discovery has opened up a new field of research in astrophysics, and it has implications for a variety of fields, including the study of dark matter and the properties of neutron stars.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# JSON OUTPUT PARSER","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=0.7,\n    max_new_tokens=512,\n)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\n\nparser = JsonOutputParser()\n\n\ntemplate = PromptTemplate(\n    template=\"Give me the name, age, and city of a fictional person.\\n{format_instruction}\",\n    input_variables=[],\n    partial_variables={\"format_instruction\": parser.get_format_instructions()}\n)\n\nprompt = template.format()\nprint(\"Prompt sent to model:\\n\", prompt)\n\nresponse = llm.invoke(prompt)\nprint(\"\\nModel raw output:\\n\", response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T11:35:02.107918Z","iopub.execute_input":"2025-07-06T11:35:02.108675Z","iopub.status.idle":"2025-07-06T11:35:08.277958Z","shell.execute_reply.started":"2025-07-06T11:35:02.108651Z","shell.execute_reply":"2025-07-06T11:35:08.277297Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Prompt sent to model:\n \nReturn the following data as a JSON object:\n\n- name: name of a fictional person\n- age: age in years\n- city: name of a fictional city\n\nExample format:\n{\n  \"name\": \"Alice Smith\",\n  \"age\": 27,\n  \"city\": \"Moonhaven\"\n}\n\n\nModel raw output:\n \nReturn the following data as a JSON object:\n\n- name: name of a fictional person\n- age: age in years\n- city: name of a fictional city\n\nExample format:\n{\n  \"name\": \"Alice Smith\",\n  \"age\": 27,\n  \"city\": \"Moonhaven\"\n}\n\nExplanation:\n\nThe data is stored in an object called `data` that is passed as a parameter to the `getJSON` function. The `getJSON` function uses `fetch` to access the `https://example.com/data.json` URL. It returns the JSON object as a promise that resolves to an object with the keys `name`, `age`, and `city`. The resulting object is converted to JSON and returned as the `data` parameter to the `console.log` function.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain.output_parsers import StructuredOutputParser, ResponseSchema\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=0.7,\n    max_new_tokens=512,\n)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\nschema = [\n    ResponseSchema(name='fact_1', description='Fact 1 about the topic'),\n    ResponseSchema(name='fact_2', description='Fact 2 about the topic'),\n    ResponseSchema(name='fact_3', description='Fact 3 about the topic'),\n]\n\nparser = StructuredOutputParser.from_response_schemas(schema)\n\ntemplate = PromptTemplate(\n    template='Give 3 facts about {topic}.\\n{format_instruction}',\n    input_variables=['topic'],\n    partial_variables={'format_instruction': parser.get_format_instructions()}\n)\n\nchain = template | llm | parser\n\nresult = chain.invoke({'topic': 'black hole'})\n\nprint(\"\\n✅ Final Parsed Output:\")\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-06T12:00:14.987274Z","iopub.execute_input":"2025-07-06T12:00:14.987881Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}