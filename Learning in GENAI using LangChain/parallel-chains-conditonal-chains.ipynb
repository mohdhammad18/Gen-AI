{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install langchain\n!pip install langchain-huggingface","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:39:15.522771Z","iopub.execute_input":"2025-07-07T05:39:15.522947Z","iopub.status.idle":"2025-07-07T05:39:30.473174Z","shell.execute_reply.started":"2025-07-07T05:39:15.522932Z","shell.execute_reply":"2025-07-07T05:39:30.472478Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.49->langchain)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed packaging-24.2\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\nCollecting langchain-core<1.0.0,>=0.3.65 (from langchain-huggingface)\n  Downloading langchain_core-0.3.68-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\nRequirement already satisfied: huggingface-hub>=0.30.2 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.31.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.2->langchain-huggingface) (1.1.0)\nCollecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface)\n  Downloading langsmith-0.4.4-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.11.4)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.30.2->langchain-huggingface) (2025.4.26)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (0.14.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain-huggingface) (1.3.1)\nDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\nDownloading langchain_core-0.3.68-py3-none-any.whl (441 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.4/441.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.7/367.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langsmith, langchain-core, langchain-huggingface\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.3.23\n    Uninstalling langsmith-0.3.23:\n      Successfully uninstalled langsmith-0.3.23\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.50\n    Uninstalling langchain-core-0.3.50:\n      Successfully uninstalled langchain-core-0.3.50\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.22 requires langsmith<0.4,>=0.1.17, but you have langsmith 0.4.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-core-0.3.68 langchain-huggingface-0.3.0 langsmith-0.4.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda\nfrom langchain.schema.runnable import RunnableParallel\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=1.0,\n    max_new_tokens=512,\n)\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\nprompt1 = PromptTemplate(\n    template='Generate short and simple notes from the following text \\n {text}',\n    input_variables=['text']\n)\n\nprompt2 = PromptTemplate(\n    template='Generate 5 short question answers from the following text \\n {text}',\n    input_variables=['text']\n)\n\nprompt3 = PromptTemplate(\n    template='Merge the provided notes and quiz into a single document \\n notes -> {notes} and quiz -> {quiz}',\n    input_variables=['notes', 'quiz']\n)\n\nparser = StrOutputParser()\nwrap_text_as_dict = RunnableLambda(lambda x: {'notes': x})\nwrap_text_as_dict1 = RunnableLambda(lambda x: {'quiz': x})\n\n\n\nparallel_chain = RunnableParallel({\n    'notes': prompt1 | llm | parser | wrap_text_as_dict,\n    'quiz': prompt2 | llm | parser |wrap_text_as_dict1\n})\n\nmerge_chain = prompt3 | llm | parser\n\nchain = parallel_chain | merge_chain\n\ntext = \"\"\"\nSupport vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n\nThe advantages of support vector machines are:\n\nEffective in high dimensional spaces.\n\nStill effective in cases where number of dimensions is greater than the number of samples.\n\nUses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n\nVersatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n\nThe disadvantages of support vector machines include:\n\nIf the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n\nSVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n\nThe support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\n\"\"\"\n\nresult = chain.invoke({'text':text})\n\nprint(result)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:11:04.238718Z","iopub.execute_input":"2025-07-07T05:11:04.239066Z","iopub.status.idle":"2025-07-07T05:19:10.382703Z","shell.execute_reply.started":"2025-07-07T05:11:04.239029Z","shell.execute_reply":"2025-07-07T05:19:10.381220Z"}},"outputs":[{"name":"stderr","text":"2025-07-07 05:11:20.985832: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751865081.191694      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751865081.251295      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4d142779874a39a5a86ff886e8beee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"361ad8814e96415e9b7ba29c5b025d46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d6fa884fc944b8ad3dfda9e055f048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8db4c2feed8c4492871c073a7337aeea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b165babe32a4265b53f3418c19d15b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7edb51a07e6245499c005582677955e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2877de2ad4634d36ac60c04a042a6ad7"}},"metadata":{}},{"name":"stderr","text":"Device set to use cpu\nThis is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n","output_type":"stream"},{"name":"stdout","text":"Merge the provided notes and quiz into a single document \n notes -> {'notes': \"Generate short and simple notes from the following text \\n \\nSupport vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\\n\\nThe advantages of support vector machines are:\\n\\nEffective in high dimensional spaces.\\n\\nStill effective in cases where number of dimensions is greater than the number of samples.\\n\\nUses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\\n\\nVersatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\\n\\nThe disadvantages of support vector machines include:\\n\\nIf the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\\n\\nSVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\\n\\nThe support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\\n\\nLearning a linear SVM is done by minimizing the mean-squared error between the target variable and the output vector (that is the optimal decision boundary), which is called in SVM in the formulation.\\n\\nThis formulation defines a function f(X) = -b*log(1 + e^(-a^T X)) + b^T W^H X, and the gradient is f(W^TZ|X), where Z is the support vector, W is the weight matrix, and Z contains the support vector and a matrix element of -s, to represent the contribution of z. By optimizing this, one obtains the solution Z = argmin_Z|Z^tw(z)-a(z)|^2.\\n\\nProbabilities can be estimated using soft or hard thresholding, i.e. Using a threshold to split data into training and testing sets.\\n\\nExamples in scikit-learn include a two class classification problem.\\n\\nThe algorithm has a time complexity O(n^3), where 'n' is the number of samples.\\n\\nThe code for a SVM with a RBF Kernel can be found in scikit-learn.\\n\\nHere's the training code:\\n\\nCreate training dataset:\\n\\nWe now create the training dataset, which contains n-pairs of samples - where n is the number of samples and p is the number of features.\\n\\nX_train_samples: numpy array of shape n*p\\nX_train_labels: numpy array of shape n\\n\\nX_train_samples is a dataset holding input samples as rows and corresponding class labels as columns. As we will be fitting a SVM, each row in X_train_samples will represent a training sample.\\n\\ny_train_labels: numpy array of shape n\\n\\ny_train_labels is a label matrix (n rows x 1 column) for the training set. 0 if the corresponding example belongs to the 0 class, 1 if it belongs to the 1 class.\\n\\nCompute training labels:\\n\\nNext, we convert the labels into binary (0/1) format so that the soft thresholding can be used.\\n\\nFor binary classifier, we take the binary output as:\\n\\ny_train_labels = (y_train_labels > 0.5).astype(int)\\n\\nIf you want\"} and quiz -> {'quiz': 'Generate 5 short question answers from the following text \\n \\nSupport vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\\n\\nThe advantages of support vector machines are:\\n\\nEffective in high dimensional spaces.\\n\\nStill effective in cases where number of dimensions is greater than the number of samples.\\n\\nUses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\\n\\nVersatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\\n\\nThe disadvantages of support vector machines include:\\n\\nIf the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\\n\\nSVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\\n\\nThe support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\\n\\nThe following code snippet demonstrates how to fit a SVM to Lung Cancer data:\\n\\n```python\\nfrom sklearn.datasets import load_breast_cancer\\n\\nfrom sklearn.model_selection import train_test_split\\n\\nfrom sklearn.svm import SVC\\n\\ndata = load_breast_cancer().data\\ntarget = load_breast_cancer().target\\n\\nX_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\\n\\nmodel = SVC(kernel=\\'rbf\\')\\nmodel.fit(X_train, y_train)\\n\\nscores = {}\\nfor (X_i, y_i), (X_test_i, y_test_i) in load_breast_cancer().data_sampler().test_loader():\\n    predict, scores[X_i] = model.decree_test(X_test_i, y_test_i)\\n\\nprint(f\\'Accuracy of SVM regression on training data: {(sum(scores.values()) / len(scores)) * 100:.2f}%\\')\\nprint(f\\'Accuracy of SVM regression on testing data: {(sum(scores.values()) / len(scores)) * 100:.2f}%\\') ```\\n\\nTo get detailed information about supported feature types and settings for SVM\\'s kernel and regularization term, use the `decree` method with parameter `scoring=\"precision_precision\"`. \\n\\nTo choose the kernel function from scikit-learn, specify an external function that takes two arguments `x` and `y`. It should return 1 for a valid pair of points and 0 for invalid (outliers). For example, we can define a custom kernel that returns 1 for any vector `X` that is within a specific distance.\\n\\n```python\\nfrom sklearn.kernel_ridge import Ridge\\nfrom sklearn.metrics import score\\n\\ndef ridge_kernel(X, y):\\n    \"\"\"\\n    A function to calculate the inner product of X and y and return 1 if the distance is within a certain threshold, 0 otherwise.\\n    \"\"\"'}...```\\n\\nFinally, in your HTML document, include the `SCRIP` tag for your JavaScript/jQuery libraries (e.g. For JavaScript, `script` tag can be included in a script tag in `<head>` or `require` function can be used here):\\n\\n```html\\n<!-- HTML document goes here -->\\n<body>\\n\\n<!-- This is where the jQuery library should be included -->\\n<script src=\\\"https://code.jquery.com/jquery-3.6.0.min.js\\\"></script>\\n\\n<script>\\n\\n// Define jQuery function\\n$(function() {\\n\\n  // Get SVM model from JavaScript object\\n  var model = data.SVM;\\n\\n  // Get predictions from model as numerical array\\n  var predictions = model.predict(model.decree(X_test));\\n\\n  // Display accuracy from test set\\n  console.log(f'Test accuracy: {score(predictions, y_test)}%');\\n\\n});\\n\\n</script>\\n\\n</body>\\n</html>\\n```\\n\\nIn the above example, we provide a jQuery function for the prediction calculation and displaying using the `score()` function from the `sklearn` library's `metrics` module. \\n\\nHere's the modified version of the HTML document with the JSPM (JS Package Manager) dependency.\\n\\n```html\\n<!-- HTML document goes here -->\\n<body>\\n\\n<!-- This is where the jQuery library should be included -->\\n<script src=\\\"https://unpkg.com/bootstrap@4/dist/js/bootstrap.min.js\\\"></script>\\n<script src=\\\"https://cdnjs.cloudflare.intrinsic.io/libs/jquery.mines.minified.js\\\"></script>\\nscales\\n</head>\\n<body onload=window.jQuery.\\n\\n<!-- This ifr,votes and/orbitmatix examples of userdata. It-sci, a numeric,any scipt. Uses.\" \\n-n scipmins Sciveign.\"\\n.scipt, anytime\\n\\nandvisible\\n\\nsvoting and\\nives\"} This andscips and scientificn\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/graph_ascii.py\u001b[0m in \u001b[0;36m_build_sugiyama_layout\u001b[0;34m(vertices, edges)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mgrandalf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVertex\u001b[0m  \u001b[0;31m# type: ignore[import-untyped]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgrandalf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayouts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSugiyamaLayout\u001b[0m  \u001b[0;31m# type: ignore[import-untyped]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'grandalf'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3672536998.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/graph.py\u001b[0m in \u001b[0;36mprint_ascii\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;34m\"\"\"Print the graph as an ASCII art string.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: T201\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/graph.py\u001b[0m in \u001b[0;36mdraw_ascii\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunnables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_ascii\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdraw_ascii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         return draw_ascii(\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/graph_ascii.py\u001b[0m in \u001b[0;36mdraw_ascii\u001b[0;34m(vertices, edges)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mylist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0msug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_sugiyama_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvertex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msV\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/runnables/graph_ascii.py\u001b[0m in \u001b[0;36m_build_sugiyama_layout\u001b[0;34m(vertices, edges)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install grandalf to draw graphs: `pip install grandalf`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Install grandalf to draw graphs: `pip install grandalf`."],"ename":"ImportError","evalue":"Install grandalf to draw graphs: `pip install grandalf`.","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"!pip install grandalf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:41:21.955467Z","iopub.execute_input":"2025-07-07T05:41:21.955764Z","iopub.status.idle":"2025-07-07T05:41:25.150247Z","shell.execute_reply.started":"2025-07-07T05:41:21.955732Z","shell.execute_reply":"2025-07-07T05:41:25.149574Z"}},"outputs":[{"name":"stdout","text":"Collecting grandalf\n  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.0.9)\nDownloading grandalf-0.8-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: grandalf\nSuccessfully installed grandalf-0.8\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"chain.get_graph().print_ascii()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:20:41.321886Z","iopub.execute_input":"2025-07-07T05:20:41.322281Z","iopub.status.idle":"2025-07-07T05:20:41.387390Z","shell.execute_reply.started":"2025-07-07T05:20:41.322244Z","shell.execute_reply":"2025-07-07T05:20:41.386451Z"}},"outputs":[{"name":"stdout","text":"              +---------------------------+              \n              | Parallel<notes,quiz>Input |              \n              +---------------------------+              \n                   **               **                   \n                ***                   ***                \n              **                         **              \n  +----------------+                +----------------+   \n  | PromptTemplate |                | PromptTemplate |   \n  +----------------+                +----------------+   \n            *                               *            \n            *                               *            \n            *                               *            \n+---------------------+          +---------------------+ \n| HuggingFacePipeline |          | HuggingFacePipeline | \n+---------------------+          +---------------------+ \n            *                               *            \n            *                               *            \n            *                               *            \n  +-----------------+              +-----------------+   \n  | StrOutputParser |              | StrOutputParser |   \n  +-----------------+              +-----------------+   \n            *                               *            \n            *                               *            \n            *                               *            \n      +--------+                        +--------+       \n      | Lambda |                        | Lambda |       \n      +--------+***                   **+--------+       \n                   **               **                   \n                     ***         ***                     \n                        **     **                        \n             +----------------------------+              \n             | Parallel<notes,quiz>Output |              \n             +----------------------------+              \n                            *                            \n                            *                            \n                            *                            \n                   +----------------+                    \n                   | PromptTemplate |                    \n                   +----------------+                    \n                            *                            \n                            *                            \n                            *                            \n                +---------------------+                  \n                | HuggingFacePipeline |                  \n                +---------------------+                  \n                            *                            \n                            *                            \n                            *                            \n                  +-----------------+                    \n                  | StrOutputParser |                    \n                  +-----------------+                    \n                            *                            \n                            *                            \n                            *                            \n                +-----------------------+                \n                | StrOutputParserOutput |                \n                +-----------------------+                \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nfrom langchain_huggingface import HuggingFacePipeline\nfrom langchain_core.prompts import PromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda\nfrom langchain_core.output_parsers import PydanticOutputParser\nfrom pydantic import BaseModel, Field\nfrom typing import Literal\n\nmodel_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(model_id)\n\nhf_pipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    do_sample=True,\n    temperature=0.5,\n    max_new_tokens=512,\n)\n\nllm = HuggingFacePipeline(pipeline=hf_pipeline)\n\nparser = StrOutputParser()\nwrap_text_as_dict = RunnableLambda(lambda x: {'sentiment': x})\n\nclass Feedback(BaseModel):\n    sentiment: Literal['positive', 'negative'] = Field(description='Give the sentiment of the feedback')\n\nprompt1 = PromptTemplate(\n    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n',\n    input_variables=['feedback'],\n)\n\nclassifier_chain = prompt1 | llm | parser | wrap_text_as_dict\n\nprompt2 = PromptTemplate(\n    template='Write an appropriate response to this positive feedback \\n {feedback}',\n    input_variables=['feedback']\n)\n\nprompt3 = PromptTemplate(\n    template='Write an appropriate response to this negative feedback \\n {feedback}',\n    input_variables=['feedback']\n)\n\nbranch_chain = RunnableBranch(\n    (lambda x:x[\"sentiment\"] == 'positive', prompt2 | llm | parser),\n    (lambda x:x[\"sentiment\"] == 'negative', prompt3 | llm | parser),\n    RunnableLambda(lambda x: \"could not find sentiment\")\n)\n\n\nchain = classifier_chain | branch_chain\n\nprint(chain.invoke({'feedback': 'This is a beautiful phone'}))\n\nchain.get_graph().print_ascii()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T05:47:28.003256Z","iopub.execute_input":"2025-07-07T05:47:28.003969Z","iopub.status.idle":"2025-07-07T05:47:43.436976Z","shell.execute_reply.started":"2025-07-07T05:47:28.003943Z","shell.execute_reply":"2025-07-07T05:47:43.436353Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"could not find sentiment\n    +-------------+      \n    | PromptInput |      \n    +-------------+      \n            *            \n            *            \n            *            \n  +----------------+     \n  | PromptTemplate |     \n  +----------------+     \n            *            \n            *            \n            *            \n+---------------------+  \n| HuggingFacePipeline |  \n+---------------------+  \n            *            \n            *            \n            *            \n  +-----------------+    \n  | StrOutputParser |    \n  +-----------------+    \n            *            \n            *            \n            *            \n      +--------+         \n      | Lambda |         \n      +--------+         \n            *            \n            *            \n            *            \n      +--------+         \n      | Branch |         \n      +--------+         \n            *            \n            *            \n            *            \n    +--------------+     \n    | BranchOutput |     \n    +--------------+     \n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}